{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the post hoc dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import parmap\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from imagen_posthocloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plot_results_posthoc import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 48\n",
      "Set CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "print(f'Available CPU cores: {num_cores}')\n",
    "num_cores = math.floor(num_cores/3)\n",
    "print(f'Set CPU cores: {num_cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/ritter/share/data/IMAGEN\"\n",
    "posthoc = IMAGEN_posthoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the [INSTRUMENT](https://imagen-europe.com/resources/imagen-dataset/documentation/) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect the selected instrument files from IMAGEN_RAW and store in posthoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>set_INSTRUMENT()</i> in <i>imagen_posthocloader.py</i>, and load the file and save it as <b> all_*.csv</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrument\n",
    "## Demographic\n",
    "PBQ   = posthoc.set_INSTRUMENT('PBQ')#, save=True)\n",
    "GEN   = posthoc.set_INSTRUMENT('GEN')#, save=True)\n",
    "LEQ   = posthoc.set_INSTRUMENT('LEQ')#, save=True)\n",
    "# DAWBA\n",
    "# CANTAB\n",
    "NEO   = posthoc.set_INSTRUMENT('NEO')#, save=True)\n",
    "SURPS = posthoc.set_INSTRUMENT('SURPS')#, save=True)\n",
    "TCI = posthoc.set_INSTRUMENT('TCI')#, save=True)\n",
    "BSI = posthoc.set_INSTRUMENT('BSI')#, save=True)\n",
    "# KIRBY\n",
    "# BIS-11\n",
    "# CSI\n",
    "# PHQ\n",
    "# CES-D\n",
    "# ANXDX\n",
    "# CAPE\n",
    "# SDQ\n",
    "# IRI\n",
    "# RRS\n",
    "# PALP\n",
    "## Social\n",
    "# CTQ   = posthoc.set_INSTRUMENT('CTQ')#, save=True)\n",
    "CTQ_MD = posthoc.set_INSTRUMENT('CTQ_MD')#, save=True)\n",
    "CTS   = posthoc.set_INSTRUMENT('CTS')#, save=True)\n",
    "PANAS = posthoc.set_INSTRUMENT('PANAS')#, save=True)\n",
    "# MINI5\n",
    "## Substance Use\n",
    "MAST = posthoc.set_INSTRUMENT('MAST')#, save=True)\n",
    "FTND  = posthoc.set_INSTRUMENT('FTND')#, save=True)\n",
    "# DAST\n",
    "# SCID\n",
    "# RAPI\n",
    "# DMQ\n",
    "# Bully Questionnaire\n",
    "# ESPAD\n",
    "# TLFB\n",
    "# AUDIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the HDF5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect the HDF5 files from h5files and save in posthoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>set_HDF5()</i> in <i>imagen_posthocloader.py</i>, and load the file and save it as <b> all_*.csv</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hdf5\n",
    "BINGE = posthoc.set_HDF5('Binge')#, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Session', 'y', 'Dataset', 'Sex', 'Site', 'Class'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general information of the hdf5\n",
    "BINGE.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the RUN data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect the RUN file from results and save in posthoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>set_RUN()</i> in <i>imagen_posthocloader.py</i>, and load the file and save it as <b> all_*.csv</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "RUN = posthoc.set_RUN('../../results/holdout_all-tp-clean_run.csv')#, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['i', 'o', 'io', 'technique', 'Session', 'Trial', 'path', 'n_samples',\n",
       "       'n_samples_cc', 'i_is_conf', 'o_is_conf', 'Model', 'model_SVM-rbf__C',\n",
       "       'model_SVM-rbf__gamma', 'runtime', 'model_SVM-lin__C',\n",
       "       'model_GB__learning_rate', 'model_LR__C', 'train_score', 'valid_score',\n",
       "       'test_score', 'roc_auc', 'holdout_score', 'holdout_roc_auc', 'dataset',\n",
       "       'ID', 'true_label', 'prediction', 'TP prob', 'TN prob', 'FP prob',\n",
       "       'FN prob', 'T prob', 'F prob', 'Prob', 'Predict TF', 'Model PN',\n",
       "       'Label PN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general infromation of the hdf5\n",
    "RUN.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save the INSTRUMENT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect the instrument files from posthoc into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>to_INSTRUMENT()</i> in <i>imagen_posthocloader.py</i>, and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the instrument file \n",
    "inst_list = [LEQ,                      # Demographic\n",
    "             NEO, SURPS, TCI, BSI,     # Psychological\n",
    "             CTQ_MD, CTS, PANAS,       # Social\n",
    "             MAST, FTND]               # Substance use\n",
    "# save the instrument file\n",
    "INST = posthoc.to_INSTRUMENT(inst_list)#, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 ['Family valence', 'Accident valence', 'Sexuality valence', 'Autonomy valence', 'Devience valence', 'Relocation valence', 'Distress valence', 'Noscale valence', 'Overall valence', 'Family mean frequency', 'Accident mean frequency', 'Sexuality mean frequency', 'Autonomy mean frequency', 'Devience mean frequency', 'Relocation mean frequency', 'Distress mean frequency', 'Noscale mean frequency', 'Overall mean frequency', 'Openness mean', 'Conscientiousness mean', 'Extroversion mean', 'Agreeableness mean', 'Neuroticism mean', 'Anxiety Sensitivity mean', 'Hopelessness mean', 'Impulsivity mean', 'Sensation seeking mean', 'Exploratory excitability vs. Stoic rigidity', 'Impulsiveness vs. Reflection', 'Extravagance vs. Reserve', 'Disorderliness vs. Regimentation', 'Total Novelty Seeking score', 'Somatization mean', 'Obsession-Compulsion mean', 'Interpersonal Sensitivity mean', 'Depression mean', 'Anxiety mean', 'Hostility mean', 'Phobic Anxiety mean', 'Paranoid Ideation mean', 'Psychoticism mean', 'Positive Symptom Distress Index', 'Global Severity Index', 'Emotional abuse sum', 'Physical abuse sum', 'Sexual abuse sum', 'Emotional neglect sum', 'Physical neglect sum', 'Denial sum', 'MD 1', 'MD 2', 'MD 3', 'Assault mean', 'Injury mean', 'Negotiation mean', 'Psychological Aggression mean', 'Sexual Coercion mean', 'Positive Affect Score', 'Negative Affect Score', 'MAST flag', 'MAST total', 'MAST Alcohol dependency symptoms', 'MAST sum', 'Likelihood of nicotine dependence child', 'FTND Sum']\n"
     ]
    }
   ],
   "source": [
    "# general information of the instrument\n",
    "# selected ROI\n",
    "col_INST = list(INST.columns[2:].values)\n",
    "print(len(col_INST), col_INST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read the INSTRUMENT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the instrument files from posthoc into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>read_INSTRUMENT()</i> in <i>imagen_posthocloader.py</i>, and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INST = posthoc.read_INSTRUMENT('IMAGEN_INSTRUMENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Session', 'Family valence', 'Accident valence',\n",
       "       'Sexuality valence', 'Autonomy valence', 'Devience valence',\n",
       "       'Relocation valence', 'Distress valence', 'Noscale valence',\n",
       "       'Overall valence', 'Family mean frequency', 'Accident mean frequency',\n",
       "       'Sexuality mean frequency', 'Autonomy mean frequency',\n",
       "       'Devience mean frequency', 'Relocation mean frequency',\n",
       "       'Distress mean frequency', 'Noscale mean frequency',\n",
       "       'Overall mean frequency', 'Openness mean', 'Conscientiousness mean',\n",
       "       'Extroversion mean', 'Agreeableness mean', 'Neuroticism mean',\n",
       "       'Anxiety Sensitivity mean', 'Hopelessness mean', 'Impulsivity mean',\n",
       "       'Sensation seeking mean', 'Exploratory excitability vs. Stoic rigidity',\n",
       "       'Impulsiveness vs. Reflection', 'Extravagance vs. Reserve',\n",
       "       'Disorderliness vs. Regimentation', 'Total Novelty Seeking score',\n",
       "       'Somatization mean', 'Obsession-Compulsion mean',\n",
       "       'Interpersonal Sensitivity mean', 'Depression mean', 'Anxiety mean',\n",
       "       'Hostility mean', 'Phobic Anxiety mean', 'Paranoid Ideation mean',\n",
       "       'Psychoticism mean', 'Positive Symptom Distress Index',\n",
       "       'Global Severity Index', 'Emotional abuse sum', 'Physical abuse sum',\n",
       "       'Sexual abuse sum', 'Emotional neglect sum', 'Physical neglect sum',\n",
       "       'Denial sum', 'MD 1', 'MD 2', 'MD 3', 'Assault mean', 'Injury mean',\n",
       "       'Negotiation mean', 'Psychological Aggression mean',\n",
       "       'Sexual Coercion mean', 'Positive Affect Score',\n",
       "       'Negative Affect Score', 'MAST flag', 'MAST total',\n",
       "       'MAST Alcohol dependency symptoms', 'MAST sum',\n",
       "       'Likelihood of nicotine dependence child', 'FTND Sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general information of the instrument\n",
    "INST.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Read the HDF5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect the hdf5 files from posthoc into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>to_HDF5()</i> in <i>imagen_posthocloader.py</i>, and load the file and save it as <b> all_*.csv</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5 = posthoc.to_HDF5('all_Binge.csv')#, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the HDF5 files from posthoc into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>read_HDF5()</i> in <i>imagen_posthocloader.py</i>, and load the file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5 = posthoc.read_HDF5('IMAGEN_HDF5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Session', 'y', 'Dataset', 'Sex', 'Site', 'Class'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general information of the hdf5\n",
    "HDF5.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Read the RUN data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select the ROI of the RUN file from posthoc into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>to_RUN()</i> in <i>imagen_posthocloader.py</i>, and load the file and save it as <b> all_*.csv</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['i', 'o', 'io', 'technique', 'Session', 'Trial', 'path', 'n_samples',\n",
       "       'n_samples_cc', 'i_is_conf', 'o_is_conf', 'Model', 'model_SVM-rbf__C',\n",
       "       'model_SVM-rbf__gamma', 'runtime', 'model_SVM-lin__C',\n",
       "       'model_GB__learning_rate', 'model_LR__C', 'train_score', 'valid_score',\n",
       "       'test_score', 'roc_auc', 'holdout_score', 'holdout_roc_auc', 'dataset',\n",
       "       'ID', 'true_label', 'prediction', 'TP prob', 'TN prob', 'FP prob',\n",
       "       'FN prob', 'T prob', 'F prob', 'Prob', 'Predict TF', 'Model PN',\n",
       "       'Label PN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL = ['ID','Session','Trial','dataset','io','technique','Model',\n",
    "       'TP prob','TN prob','FP prob','FN prob','T prob','F prob','Prob',\n",
    "       'Predict TF','Model PN','Label PN','true_label','prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = posthoc.to_RUN('all_RUN.csv', COL)#, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Session', 'Trial', 'dataset', 'io', 'technique', 'Model',\n",
       "       'TP prob', 'TN prob', 'FP prob', 'FN prob', 'T prob', 'F prob', 'Prob',\n",
       "       'Predict TF', 'Model PN', 'Label PN', 'true_label', 'prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general information of the run\n",
    "RUN.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the RUN files from posthoc into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>read_RUN()</i> in <i>imagen_posthocloader.py</i>, and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = posthoc.read_RUN('IMAGEN_RUN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Session', 'Trial', 'dataset', 'io', 'technique', 'Model',\n",
       "       'TP prob', 'TN prob', 'FP prob', 'FN prob', 'T prob', 'F prob', 'Prob',\n",
       "       'Predict TF', 'Model PN', 'Label PN', 'true_label', 'prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general information of the run\n",
    "RUN.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save the post hoc dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set the dataset for analysis of diagnosis (X:FU3 == y:FU3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>to_posthoc()</i> in <i>imagen_posthocloader.py</i>, and load the file and save it as <b> all_*.csv</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = ['IMAGEN_HDF5.csv', 'IMAGEN_INSTRUMENT.csv', 'IMAGEN_RUN.csv']\n",
    "FU3 = posthoc.to_posthoc(DATA)#, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Session', 'y', 'Dataset', 'Sex', 'Site', 'Class', 'Trial',\n",
       "       'dataset', 'io', 'technique', 'Model', 'TP prob', 'TN prob', 'FP prob',\n",
       "       'FN prob', 'T prob', 'F prob', 'Prob', 'Predict TF', 'Model PN',\n",
       "       'Label PN', 'true_label', 'prediction', 'Family valence',\n",
       "       'Accident valence', 'Sexuality valence', 'Autonomy valence',\n",
       "       'Devience valence', 'Relocation valence', 'Distress valence',\n",
       "       'Noscale valence', 'Overall valence', 'Family mean frequency',\n",
       "       'Accident mean frequency', 'Sexuality mean frequency',\n",
       "       'Autonomy mean frequency', 'Devience mean frequency',\n",
       "       'Relocation mean frequency', 'Distress mean frequency',\n",
       "       'Noscale mean frequency', 'Overall mean frequency', 'Openness mean',\n",
       "       'Conscientiousness mean', 'Extroversion mean', 'Agreeableness mean',\n",
       "       'Neuroticism mean', 'Anxiety Sensitivity mean', 'Hopelessness mean',\n",
       "       'Impulsivity mean', 'Sensation seeking mean',\n",
       "       'Exploratory excitability vs. Stoic rigidity',\n",
       "       'Impulsiveness vs. Reflection', 'Extravagance vs. Reserve',\n",
       "       'Disorderliness vs. Regimentation', 'Total Novelty Seeking score',\n",
       "       'Somatization mean', 'Obsession-Compulsion mean',\n",
       "       'Interpersonal Sensitivity mean', 'Depression mean', 'Anxiety mean',\n",
       "       'Hostility mean', 'Phobic Anxiety mean', 'Paranoid Ideation mean',\n",
       "       'Psychoticism mean', 'Positive Symptom Distress Index',\n",
       "       'Global Severity Index', 'Emotional abuse sum', 'Physical abuse sum',\n",
       "       'Sexual abuse sum', 'Emotional neglect sum', 'Physical neglect sum',\n",
       "       'Denial sum', 'MD 1', 'MD 2', 'MD 3', 'Assault mean', 'Injury mean',\n",
       "       'Negotiation mean', 'Psychological Aggression mean',\n",
       "       'Sexual Coercion mean', 'Positive Affect Score',\n",
       "       'Negative Affect Score', 'MAST flag', 'MAST total',\n",
       "       'MAST Alcohol dependency symptoms', 'MAST sum',\n",
       "       'Likelihood of nicotine dependence child', 'FTND Sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general information of the instrument\n",
    "FU3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                               37058553\n",
       "Session                                               FU3\n",
       "y                                                   Binge\n",
       "Dataset                                          Training\n",
       "Sex                                                  Male\n",
       "                                                ...      \n",
       "MAST total                                             11\n",
       "MAST Alcohol dependency symptoms                        3\n",
       "MAST sum                                                8\n",
       "Likelihood of nicotine dependence child    less dependent\n",
       "FTND Sum                                                0\n",
       "Name: 1000, Length: 89, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FU3.iloc[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set the dataset for analysis of prognosis (X:FU3 != y:FU3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>read_posthoc()</i> in <i>imagen_posthocloader.py</i>, and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FU3 = posthoc.read_posthoc('IMAGEN_posthoc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Session</th>\n",
       "      <th>y</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Site</th>\n",
       "      <th>Class</th>\n",
       "      <th>Trial</th>\n",
       "      <th>dataset</th>\n",
       "      <th>io</th>\n",
       "      <th>...</th>\n",
       "      <th>Psychological Aggression mean</th>\n",
       "      <th>Sexual Coercion mean</th>\n",
       "      <th>Positive Affect Score</th>\n",
       "      <th>Negative Affect Score</th>\n",
       "      <th>MAST flag</th>\n",
       "      <th>MAST total</th>\n",
       "      <th>MAST Alcohol dependency symptoms</th>\n",
       "      <th>MAST sum</th>\n",
       "      <th>Likelihood of nicotine dependence child</th>\n",
       "      <th>FTND Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>1163495</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>AAM</td>\n",
       "      <td>0</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>positive alchololism screening</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>1163495</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>AAM</td>\n",
       "      <td>1</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>positive alchololism screening</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>1163495</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>AAM</td>\n",
       "      <td>2</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>positive alchololism screening</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>1163495</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>AAM</td>\n",
       "      <td>3</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>positive alchololism screening</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>1163495</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>AAM</td>\n",
       "      <td>4</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>positive alchololism screening</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>99875982</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>HC</td>\n",
       "      <td>2</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>99875982</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>HC</td>\n",
       "      <td>3</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>99875982</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>HC</td>\n",
       "      <td>4</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>99875982</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>HC</td>\n",
       "      <td>5</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>99875982</td>\n",
       "      <td>FU3</td>\n",
       "      <td>Binge</td>\n",
       "      <td>Holdout</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>HC</td>\n",
       "      <td>6</td>\n",
       "      <td>Holdout set</td>\n",
       "      <td>X-Binge</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less dependent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2856 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID Session      y  Dataset   Sex      Site Class  Trial  \\\n",
       "2600   1163495     FU3  Binge  Holdout  Male  Mannheim   AAM      0   \n",
       "2601   1163495     FU3  Binge  Holdout  Male  Mannheim   AAM      1   \n",
       "2602   1163495     FU3  Binge  Holdout  Male  Mannheim   AAM      2   \n",
       "2603   1163495     FU3  Binge  Holdout  Male  Mannheim   AAM      3   \n",
       "2604   1163495     FU3  Binge  Holdout  Male  Mannheim   AAM      4   \n",
       "...        ...     ...    ...      ...   ...       ...   ...    ...   \n",
       "5451  99875982     FU3  Binge  Holdout  Male   Hamburg    HC      2   \n",
       "5452  99875982     FU3  Binge  Holdout  Male   Hamburg    HC      3   \n",
       "5453  99875982     FU3  Binge  Holdout  Male   Hamburg    HC      4   \n",
       "5454  99875982     FU3  Binge  Holdout  Male   Hamburg    HC      5   \n",
       "5455  99875982     FU3  Binge  Holdout  Male   Hamburg    HC      6   \n",
       "\n",
       "          dataset       io  ... Psychological Aggression mean  \\\n",
       "2600  Holdout set  X-Binge  ...                        0.3125   \n",
       "2601  Holdout set  X-Binge  ...                        0.3125   \n",
       "2602  Holdout set  X-Binge  ...                        0.3125   \n",
       "2603  Holdout set  X-Binge  ...                        0.3125   \n",
       "2604  Holdout set  X-Binge  ...                        0.3125   \n",
       "...           ...      ...  ...                           ...   \n",
       "5451  Holdout set  X-Binge  ...                        0.2500   \n",
       "5452  Holdout set  X-Binge  ...                        0.2500   \n",
       "5453  Holdout set  X-Binge  ...                        0.2500   \n",
       "5454  Holdout set  X-Binge  ...                        0.2500   \n",
       "5455  Holdout set  X-Binge  ...                        0.2500   \n",
       "\n",
       "     Sexual Coercion mean  Positive Affect Score  Negative Affect Score  \\\n",
       "2600                  0.0                   31.0                   20.0   \n",
       "2601                  0.0                   31.0                   20.0   \n",
       "2602                  0.0                   31.0                   20.0   \n",
       "2603                  0.0                   31.0                   20.0   \n",
       "2604                  0.0                   31.0                   20.0   \n",
       "...                   ...                    ...                    ...   \n",
       "5451                  0.0                   35.0                   13.0   \n",
       "5452                  0.0                   35.0                   13.0   \n",
       "5453                  0.0                   35.0                   13.0   \n",
       "5454                  0.0                   35.0                   13.0   \n",
       "5455                  0.0                   35.0                   13.0   \n",
       "\n",
       "                           MAST flag  MAST total  \\\n",
       "2600  positive alchololism screening        17.0   \n",
       "2601  positive alchololism screening        17.0   \n",
       "2602  positive alchololism screening        17.0   \n",
       "2603  positive alchololism screening        17.0   \n",
       "2604  positive alchololism screening        17.0   \n",
       "...                              ...         ...   \n",
       "5451                             NaN         NaN   \n",
       "5452                             NaN         NaN   \n",
       "5453                             NaN         NaN   \n",
       "5454                             NaN         NaN   \n",
       "5455                             NaN         NaN   \n",
       "\n",
       "      MAST Alcohol dependency symptoms  MAST sum  \\\n",
       "2600                               3.0      14.0   \n",
       "2601                               3.0      14.0   \n",
       "2602                               3.0      14.0   \n",
       "2603                               3.0      14.0   \n",
       "2604                               3.0      14.0   \n",
       "...                                ...       ...   \n",
       "5451                               NaN       NaN   \n",
       "5452                               NaN       NaN   \n",
       "5453                               NaN       NaN   \n",
       "5454                               NaN       NaN   \n",
       "5455                               NaN       NaN   \n",
       "\n",
       "     Likelihood of nicotine dependence child FTND Sum  \n",
       "2600                          less dependent      0.0  \n",
       "2601                          less dependent      0.0  \n",
       "2602                          less dependent      0.0  \n",
       "2603                          less dependent      0.0  \n",
       "2604                          less dependent      0.0  \n",
       "...                                      ...      ...  \n",
       "5451                          less dependent      0.0  \n",
       "5452                          less dependent      0.0  \n",
       "5453                          less dependent      0.0  \n",
       "5454                          less dependent      0.0  \n",
       "5455                          less dependent      0.0  \n",
       "\n",
       "[2856 rows x 89 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FU3.groupby('Dataset').get_group('Holdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5456 entries, 0 to 5455\n",
      "Data columns (total 89 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   ID                                           5456 non-null   int64  \n",
      " 1   Session                                      5456 non-null   object \n",
      " 2   y                                            5456 non-null   object \n",
      " 3   Dataset                                      5456 non-null   object \n",
      " 4   Sex                                          5456 non-null   object \n",
      " 5   Site                                         5456 non-null   object \n",
      " 6   Class                                        5456 non-null   object \n",
      " 7   Trial                                        5456 non-null   int64  \n",
      " 8   dataset                                      5456 non-null   object \n",
      " 9   io                                           5456 non-null   object \n",
      " 10  technique                                    5456 non-null   object \n",
      " 11  Model                                        5456 non-null   object \n",
      " 12  TP prob                                      2331 non-null   float64\n",
      " 13  TN prob                                      1529 non-null   float64\n",
      " 14  FP prob                                      803 non-null    float64\n",
      " 15  FN prob                                      793 non-null    float64\n",
      " 16  T prob                                       3860 non-null   float64\n",
      " 17  F prob                                       1596 non-null   float64\n",
      " 18  Prob                                         5456 non-null   object \n",
      " 19  Predict TF                                   5456 non-null   object \n",
      " 20  Model PN                                     5456 non-null   object \n",
      " 21  Label PN                                     5456 non-null   object \n",
      " 22  true_label                                   5456 non-null   float64\n",
      " 23  prediction                                   5456 non-null   float64\n",
      " 24  Family valence                               5396 non-null   float64\n",
      " 25  Accident valence                             5396 non-null   float64\n",
      " 26  Sexuality valence                            5396 non-null   float64\n",
      " 27  Autonomy valence                             5396 non-null   float64\n",
      " 28  Devience valence                             5396 non-null   float64\n",
      " 29  Relocation valence                           5396 non-null   float64\n",
      " 30  Distress valence                             5396 non-null   float64\n",
      " 31  Noscale valence                              5396 non-null   float64\n",
      " 32  Overall valence                              5396 non-null   float64\n",
      " 33  Family mean frequency                        5396 non-null   float64\n",
      " 34  Accident mean frequency                      5396 non-null   float64\n",
      " 35  Sexuality mean frequency                     5396 non-null   float64\n",
      " 36  Autonomy mean frequency                      5396 non-null   float64\n",
      " 37  Devience mean frequency                      5396 non-null   float64\n",
      " 38  Relocation mean frequency                    5396 non-null   float64\n",
      " 39  Distress mean frequency                      5396 non-null   float64\n",
      " 40  Noscale mean frequency                       5396 non-null   float64\n",
      " 41  Overall mean frequency                       5396 non-null   float64\n",
      " 42  Openness mean                                5400 non-null   float64\n",
      " 43  Conscientiousness mean                       5400 non-null   float64\n",
      " 44  Extroversion mean                            5400 non-null   float64\n",
      " 45  Agreeableness mean                           5400 non-null   float64\n",
      " 46  Neuroticism mean                             5400 non-null   float64\n",
      " 47  Anxiety Sensitivity mean                     5396 non-null   float64\n",
      " 48  Hopelessness mean                            5396 non-null   float64\n",
      " 49  Impulsivity mean                             5396 non-null   float64\n",
      " 50  Sensation seeking mean                       5396 non-null   float64\n",
      " 51  Exploratory excitability vs. Stoic rigidity  5396 non-null   float64\n",
      " 52  Impulsiveness vs. Reflection                 5396 non-null   float64\n",
      " 53  Extravagance vs. Reserve                     5396 non-null   float64\n",
      " 54  Disorderliness vs. Regimentation             5396 non-null   float64\n",
      " 55  Total Novelty Seeking score                  5396 non-null   float64\n",
      " 56  Somatization mean                            5256 non-null   float64\n",
      " 57  Obsession-Compulsion mean                    5256 non-null   float64\n",
      " 58  Interpersonal Sensitivity mean               5256 non-null   float64\n",
      " 59  Depression mean                              5256 non-null   float64\n",
      " 60  Anxiety mean                                 5256 non-null   float64\n",
      " 61  Hostility mean                               5256 non-null   float64\n",
      " 62  Phobic Anxiety mean                          5256 non-null   float64\n",
      " 63  Paranoid Ideation mean                       5256 non-null   float64\n",
      " 64  Psychoticism mean                            5256 non-null   float64\n",
      " 65  Positive Symptom Distress Index              5256 non-null   float64\n",
      " 66  Global Severity Index                        5256 non-null   float64\n",
      " 67  Emotional abuse sum                          4784 non-null   float64\n",
      " 68  Physical abuse sum                           4784 non-null   float64\n",
      " 69  Sexual abuse sum                             4784 non-null   float64\n",
      " 70  Emotional neglect sum                        4784 non-null   float64\n",
      " 71  Physical neglect sum                         4784 non-null   float64\n",
      " 72  Denial sum                                   4784 non-null   float64\n",
      " 73  MD 1                                         4784 non-null   float64\n",
      " 74  MD 2                                         4784 non-null   float64\n",
      " 75  MD 3                                         4784 non-null   float64\n",
      " 76  Assault mean                                 5156 non-null   float64\n",
      " 77  Injury mean                                  5156 non-null   float64\n",
      " 78  Negotiation mean                             5156 non-null   float64\n",
      " 79  Psychological Aggression mean                5156 non-null   float64\n",
      " 80  Sexual Coercion mean                         5156 non-null   float64\n",
      " 81  Positive Affect Score                        5332 non-null   float64\n",
      " 82  Negative Affect Score                        5332 non-null   float64\n",
      " 83  MAST flag                                    4052 non-null   object \n",
      " 84  MAST total                                   4052 non-null   float64\n",
      " 85  MAST Alcohol dependency symptoms             4052 non-null   float64\n",
      " 86  MAST sum                                     4052 non-null   float64\n",
      " 87  Likelihood of nicotine dependence child      5456 non-null   object \n",
      " 88  FTND Sum                                     5456 non-null   float64\n",
      "dtypes: float64(71), int64(2), object(16)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "FU3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Session', 'y', 'Dataset', 'Sex', 'Site', 'Class', 'Trial', 'dataset', 'io', 'technique', 'Model', 'TP prob', 'TN prob', 'FP prob', 'FN prob', 'T prob', 'F prob', 'Prob', 'Predict TF', 'Model PN', 'Label PN', 'true_label', 'prediction', 'Family valence', 'Accident valence', 'Sexuality valence', 'Autonomy valence', 'Devience valence', 'Relocation valence', 'Distress valence', 'Noscale valence', 'Overall valence', 'Family mean frequency', 'Accident mean frequency', 'Sexuality mean frequency', 'Autonomy mean frequency', 'Devience mean frequency', 'Relocation mean frequency', 'Distress mean frequency', 'Noscale mean frequency', 'Overall mean frequency', 'Openness mean', 'Conscientiousness mean', 'Extroversion mean', 'Agreeableness mean', 'Neuroticism mean', 'Anxiety Sensitivity mean', 'Hopelessness mean', 'Impulsivity mean', 'Sensation seeking mean', 'Exploratory excitability vs. Stoic rigidity', 'Impulsiveness vs. Reflection', 'Extravagance vs. Reserve', 'Disorderliness vs. Regimentation', 'Total Novelty Seeking score', 'Somatization mean', 'Obsession-Compulsion mean', 'Interpersonal Sensitivity mean', 'Depression mean', 'Anxiety mean', 'Hostility mean', 'Phobic Anxiety mean', 'Paranoid Ideation mean', 'Psychoticism mean', 'Positive Symptom Distress Index', 'Global Severity Index', 'Emotional abuse sum', 'Physical abuse sum', 'Sexual abuse sum', 'Emotional neglect sum', 'Physical neglect sum', 'Denial sum', 'MD 1', 'MD 2', 'MD 3', 'Assault mean', 'Injury mean', 'Negotiation mean', 'Psychological Aggression mean', 'Sexual Coercion mean', 'Positive Affect Score', 'Negative Affect Score', 'MAST flag', 'MAST total', 'MAST Alcohol dependency symptoms', 'MAST sum', 'Likelihood of nicotine dependence child', 'FTND Sum']\n"
     ]
    }
   ],
   "source": [
    "# general information of the instrument\n",
    "print(list(FU3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                               37058553\n",
      "Session                                               FU3\n",
      "y                                                   Binge\n",
      "Dataset                                          Training\n",
      "Sex                                                  Male\n",
      "                                                ...      \n",
      "MAST total                                             11\n",
      "MAST Alcohol dependency symptoms                        3\n",
      "MAST sum                                                8\n",
      "Likelihood of nicotine dependence child    less dependent\n",
      "FTND Sum                                                0\n",
      "Name: 1000, Length: 89, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(FU3.iloc[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Get the SHAP value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To do) merge the command into one method: to_SHAP() in posthocloader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosis: X:FU3 to y:FU3 in holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load the data and the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = posthoc.get_model(\"../../results/newlbls-clean-fu3-espad-fu3-19a-binge-*/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dir = \"newholdout-clean-fu3-espad-fu3-19a-binge-n102.h5\"\n",
    "# load the holdout data\n",
    "ho_X, ho_X_col_names, ho_list = posthoc.get_holdout_data(holdout_dir, group=True)\n",
    "# print(f\"Holdout dataset: {ho_X.shape}, {len(ho_X_col_names)}, \"\n",
    "#       f\"{ho_list[0].shape}, {ho_list[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of holdout set: 7\n"
     ]
    }
   ],
   "source": [
    "# generate the SHAP input list of the holdout ONLY SVM-rbf\n",
    "ho_INPUT = posthoc.get_list(MODELS, ho_X, \"SVM-RBF\")\n",
    "# print(f\"Number of training set: {len(tr_INPUT)}\\n\\n\" # , One example: {tr_INPUT[0:1]}\\n\\n\"\n",
    "print(f\"Number of holdout set: {len(ho_INPUT)}\")#, {ho_INPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Compute the SHAP value </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One by one\n",
    "# INPUT = tr_INPUT[0]\n",
    "# start_time = time.time()\n",
    "# _ = posthoc.get_SHAP(INPUT, 'FU3')\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.797645568847656e-05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Multi processing\n",
    "INPUT = ho_INPUT\n",
    "start_time = time.time()\n",
    "# _ = parmap.map(posthoc.get_SHAP, INPUT, 'FU3', pm_pbar=True, pm_processes=num_cores)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prognosis: X:FU2 to y:FU3 in holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load the data and the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = posthoc.get_model(\"../../results/newlbls-clean-fu2-espad-fu3-19a-binge-*/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dir = \"newholdout-clean-fu2-espad-fu3-19a-binge-n102.h5\"\n",
    "# load the holdout data\n",
    "ho_X, ho_X_col_names, ho_list = posthoc.get_holdout_data(holdout_dir, group=True)\n",
    "# print(f\"Holdout dataset: {ho_X.shape}, {len(ho_X_col_names)}, \"\n",
    "#       f\"{ho_list[0].shape}, {ho_list[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of holdout set: 7\n"
     ]
    }
   ],
   "source": [
    "# generate the SHAP input list of the holdout ONLY SVM-rbf\n",
    "ho_INPUT = posthoc.get_list(MODELS, ho_X, \"SVM-LIN\")\n",
    "# print(f\"Number of training set: {len(tr_INPUT)}\\n\\n\" # , One example: {tr_INPUT[0:1]}\\n\\n\"\n",
    "print(f\"Number of holdout set: {len(ho_INPUT)}\")#, {ho_INPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Compute the SHAP value </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One by one\n",
    "# INPUT = tr_INPUT[0]\n",
    "# start_time = time.time()\n",
    "# _ = posthoc.get_SHAP(INPUT, 'FU2')\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.965896606445312e-05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Multi processing\n",
    "INPUT = ho_INPUT\n",
    "start_time = time.time()\n",
    "# _ = parmap.map(posthoc.get_SHAP, INPUT, 'FU2', pm_pbar=True, pm_processes=num_cores)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prognosis: X:BL to y:FU3 in holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load the data and the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = posthoc.get_model(\"../../results/newlbls-clean-bl-espad-fu3-19a-binge-*/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dir = \"newholdout-clean-bl-espad-fu3-19a-binge-n102.h5\"\n",
    "# load the holdout data\n",
    "ho_X, ho_X_col_names, ho_list = posthoc.get_holdout_data(holdout_dir, group=True)\n",
    "# print(f\"Holdout dataset: {ho_X.shape}, {len(ho_X_col_names)}, \"\n",
    "#       f\"{ho_list[0].shape}, {ho_list[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of holdout set: 7\n"
     ]
    }
   ],
   "source": [
    "# generate the SHAP input list of the holdout ONLY SVM-rbf\n",
    "ho_INPUT = posthoc.get_list(MODELS, ho_X, \"LR\")\n",
    "# print(f\"Number of training set: {len(tr_INPUT)}\\n\\n\" # , One example: {tr_INPUT[0:1]}\\n\\n\"\n",
    "print(f\"Number of holdout set: {len(ho_INPUT)}\")#, {ho_INPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Compute the SHAP value </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One by one\n",
    "# INPUT = tr_INPUT[0]\n",
    "# start_time = time.time()\n",
    "# _ = posthoc.get_SHAP(INPUT, 'BL')\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00011110305786132812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Multi processing\n",
    "INPUT = ho_INPUT\n",
    "start_time = time.time()\n",
    "# _ = parmap.map(posthoc.get_SHAP, INPUT, 'BL', pm_pbar=True, pm_processes=num_cores)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosis: X:FU3 to y:FU3 in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS = posthoc.get_model(\"../../results/newlbls-clean-fu3-espad-fu3-19a-binge-*/*/\")\n",
    "# train_dir = \"newlbls-clean-fu3-espad-fu3-19a-binge-n650.h5\"\n",
    "# # load the training data\n",
    "# tr_X, tr_X_col_names, tr_list = SHAP.get_train_data(train_dir, group=True)\n",
    "# print(f\"Training dataset: {tr_X.shape}, {len(tr_X_col_names)}, {tr_list[0].shape}\")\n",
    "# # generate the SHAP input list of the training\n",
    "# tr_INPUT = SHAP.get_list(MODELS, tr_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Save the mean|SHAP| value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the feature derivatives and mean, std |SHAP value|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>to_abs_SHAP()</i> in <i>imagen_posthocloader.py</i>, and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FU3\n",
    "H5_FU3 = \"newholdout-clean-fu3-espad-fu3-19a-binge-n102.h5\"\n",
    "GB_FU3 = [\"GB0_FU3.sav\", \"GB1_FU3.sav\", \"GB2_FU3.sav\", \"GB3_FU3.sav\", \"GB4_FU3.sav\", \"GB5_FU3.sav\", \"GB6_FU3.sav\"]\n",
    "LR_FU3 = [\"LR0_FU3.sav\", \"LR1_FU3.sav\", \"LR2_FU3.sav\", \"LR3_FU3.sav\", \"LR4_FU3.sav\", \"LR5_FU3.sav\", \"LR6_FU3.sav\"]\n",
    "SVM_lin_FU3 = [\"SVM-lin0_FU3.sav\", \"SVM-lin1_FU3.sav\", \"SVM-lin2_FU3.sav\", \"SVM-lin3_FU3.sav\", \"SVM-lin4_FU3.sav\", \"SVM-lin5_FU3.sav\", \"SVM-lin6_FU3.sav\"]\n",
    "SVM_rbf_FU3 = [\"SVM-rbf0_FU3.sav\", \"SVM-rbf1_FU3.sav\", \"SVM-rbf2_FU3.sav\", \"SVM-rbf3_FU3.sav\", \"SVM-rbf4_FU3.sav\", \"SVM-rbf5_FU3.sav\", \"SVM-rbf6_FU3.sav\"]\n",
    "\n",
    "# FU2\n",
    "H5_FU2 = \"newholdout-clean-fu2-espad-fu3-19a-binge-n102.h5\"\n",
    "GB_FU2 = [\"GB0_FU2.sav\", \"GB1_FU2.sav\", \"GB2_FU2.sav\", \"GB3_FU2.sav\", \"GB4_FU2.sav\", \"GB5_FU2.sav\", \"GB6_FU2.sav\"]\n",
    "LR_FU2 = [\"LR0_FU2.sav\", \"LR1_FU2.sav\", \"LR2_FU2.sav\", \"LR3_FU2.sav\", \"LR4_FU2.sav\", \"LR5_FU2.sav\", \"LR6_FU2.sav\"]\n",
    "SVM_lin_FU2 = [\"SVM-lin0_FU2.sav\", \"SVM-lin1_FU2.sav\", \"SVM-lin2_FU2.sav\", \"SVM-lin3_FU2.sav\", \"SVM-lin4_FU2.sav\", \"SVM-lin5_FU2.sav\", \"SVM-lin6_FU2.sav\"]\n",
    "SVM_rbf_FU2 = [\"SVM-rbf0_FU2.sav\", \"SVM-rbf1_FU2.sav\", \"SVM-rbf2_FU2.sav\", \"SVM-rbf3_FU2.sav\", \"SVM-rbf4_FU2.sav\", \"SVM-rbf5_FU2.sav\", \"SVM-rbf6_FU2.sav\"]\n",
    "\n",
    "# BL\n",
    "H5_BL = \"newholdout-clean-bl-espad-fu3-19a-binge-n102.h5\"\n",
    "GB_BL = [\"GB0_BL.sav\", \"GB1_BL.sav\", \"GB2_BL.sav\", \"GB3_BL.sav\", \"GB4_BL.sav\", \"GB5_BL.sav\", \"GB6_BL.sav\"]\n",
    "LR_BL = [\"LR0_BL.sav\", \"LR1_BL.sav\", \"LR2_BL.sav\", \"LR3_BL.sav\", \"LR4_BL.sav\", \"LR5_BL.sav\", \"LR6_BL.sav\"]\n",
    "SVM_lin_BL = [\"SVM-lin0_BL.sav\", \"SVM-lin1_BL.sav\", \"SVM-lin2_BL.sav\", \"SVM-lin3_BL.sav\", \"SVM-lin4_BL.sav\", \"SVM-lin5_BL.sav\", \"SVM-lin6_BL.sav\"]\n",
    "SVM_rbf_BL = [\"SVM-rbf0_BL.sav\", \"SVM-rbf1_BL.sav\", \"SVM-rbf2_BL.sav\", \"SVM-rbf3_BL.sav\", \"SVM-rbf4_BL.sav\", \"SVM-rbf5_BL.sav\", \"SVM-rbf6_BL.sav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FU3\n",
    "SHAP = GB_FU3+LR_FU3+SVM_lin_FU3+SVM_rbf_FU3\n",
    "FU3_SHAP = posthoc.to_abs_SHAP(H5_FU3, SHAP, \"FU3\")#, save=True)\n",
    "\n",
    "# FU2\n",
    "SHAP = GB_FU2+LR_FU2+SVM_lin_FU2+SVM_rbf_FU2\n",
    "FU2_SHAP = posthoc.to_abs_SHAP(H5_FU2, SHAP, \"FU2\")#, save=True)\n",
    "\n",
    "# BL\n",
    "SHAP = GB_BL+LR_BL+SVM_lin_BL+SVM_rbf_BL\n",
    "BL_SHAP = posthoc.to_abs_SHAP(H5_BL, SHAP, \"BL\")#, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the mean of mean, std |SHAP value|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to <i>to_mofm_SHAP()</i> in <i>imagen_posthocloader.py</i>, and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FU3_SHAP = posthoc.read_SHAP('all_FU3_SHAP.csv')\n",
    "FU2_SHAP = posthoc.read_SHAP('all_FU2_SHAP.csv')\n",
    "BL_SHAP = posthoc.read_SHAP('all_BL_SHAP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sorted SHAP in SVM-rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = posthoc.read_SHAP('all_mofm_abs_SHAP.csv')\n",
    "DF = posthoc.to_sorted_mean_SHAP(DF, 'SVM-rbf', 'FU3')\n",
    "DF = posthoc.to_sorted_mean_SHAP(DF, 'SVM-rbf', 'FU2')\n",
    "DF = posthoc.to_sorted_mean_SHAP(DF, 'SVM-rbf', 'BL')#, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and save the SHAP value subject by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FU3\n",
    "for MD in GB_FU3:\n",
    "    posthoc.load_SHAP(H5_FU3, MD)#, save=True)\n",
    "for MD in LR_FU3:\n",
    "    posthoc.load_SHAP(H5_FU3, MD)#, save=True)\n",
    "for MD in SVM_lin_FU3:\n",
    "    posthoc.load_SHAP(H5_FU3, MD)#, save=True)\n",
    "for MD in SVM_rbf_FU3:\n",
    "    posthoc.load_SHAP(H5_FU3, MD)#, save=True)\n",
    "# FU2\n",
    "for MD in GB_FU2:\n",
    "    posthoc.load_SHAP(H5_FU2, MD)#, save=True)\n",
    "for MD in LR_FU2:\n",
    "    posthoc.load_SHAP(H5_FU2, MD)#, save=True)\n",
    "for MD in SVM_lin_FU2:\n",
    "    posthoc.load_SHAP(H5_FU2, MD)#, save=True)\n",
    "for MD in SVM_rbf_FU2:\n",
    "    posthoc.load_SHAP(H5_FU2, MD)#, save=True)\n",
    "# BL\n",
    "for MD in GB_BL:\n",
    "    posthoc.load_SHAP(H5_BL, MD)#, save=True)\n",
    "for MD in LR_BL:\n",
    "    posthoc.load_SHAP(H5_BL, MD)#, save=True)\n",
    "for MD in SVM_lin_BL:\n",
    "    posthoc.load_SHAP(H5_BL, MD)#, save=True)\n",
    "for MD in SVM_rbf_BL:\n",
    "    posthoc.load_SHAP(H5_BL, MD)#, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Case: SVM-rbf in FU3 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_rbf0_FU3 = posthoc.read_SHAP('all_SVM-rbf0_FU3_SHAP.csv')\n",
    "SVM_rbf1_FU3 = posthoc.read_SHAP('all_SVM-rbf1_FU3_SHAP.csv')\n",
    "SVM_rbf2_FU3 = posthoc.read_SHAP('all_SVM-rbf2_FU3_SHAP.csv')\n",
    "SVM_rbf3_FU3 = posthoc.read_SHAP('all_SVM-rbf3_FU3_SHAP.csv')\n",
    "SVM_rbf4_FU3 = posthoc.read_SHAP('all_SVM-rbf4_FU3_SHAP.csv')\n",
    "SVM_rbf5_FU3 = posthoc.read_SHAP('all_SVM-rbf5_FU3_SHAP.csv')\n",
    "SVM_rbf6_FU3 = posthoc.read_SHAP('all_SVM-rbf6_FU3_SHAP.csv')\n",
    "SVM_rbf_list = [SVM_rbf0_FU3, SVM_rbf1_FU3, SVM_rbf2_FU3,\n",
    "                SVM_rbf3_FU3, SVM_rbf4_FU3, SVM_rbf5_FU3, SVM_rbf6_FU3]\n",
    "SVM_rbf_FU3 = posthoc.to_SHAP(SVM_rbf_list, 'all_SVM-rbf_FU3_SHAP.csv')#, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Session</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Model</th>\n",
       "      <th>Class</th>\n",
       "      <th>T1w_cor_bankssts-lh-volume</th>\n",
       "      <th>T1w_cor_caudalanteriorcingulate-lh-volume</th>\n",
       "      <th>T1w_cor_caudalmiddlefrontal-lh-volume</th>\n",
       "      <th>T1w_cor_cuneus-lh-volume</th>\n",
       "      <th>T1w_cor_entorhinal-lh-volume</th>\n",
       "      <th>...</th>\n",
       "      <th>DTI_SFO-R_Average</th>\n",
       "      <th>DTI_SLF_Average</th>\n",
       "      <th>DTI_SLF-L_Average</th>\n",
       "      <th>DTI_SLF-R_Average</th>\n",
       "      <th>DTI_SS_Average</th>\n",
       "      <th>DTI_SS-L_Average</th>\n",
       "      <th>DTI_SS-R_Average</th>\n",
       "      <th>DTI_UNC_Average</th>\n",
       "      <th>DTI_UNC-L_Average</th>\n",
       "      <th>DTI_UNC-R_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1163495</td>\n",
       "      <td>FU3</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>AAM</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>-3.000000e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.000000e-03</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.000000e-03</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1938036</td>\n",
       "      <td>FU3</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>AAM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.000000e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2103894</td>\n",
       "      <td>FU3</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>AAM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000e-03</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-7.000000e-03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2766073</td>\n",
       "      <td>FU3</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>AAM</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000000e-03</td>\n",
       "      <td>-6.000000e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e-03</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.000000e-03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3504454</td>\n",
       "      <td>FU3</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>HC</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-1.387779e-18</td>\n",
       "      <td>5.204170e-19</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.775558e-18</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>95957207</td>\n",
       "      <td>FU3</td>\n",
       "      <td>6</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>HC</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000000e-03</td>\n",
       "      <td>1.300000e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-6.000000e-03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>97739048</td>\n",
       "      <td>FU3</td>\n",
       "      <td>6</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>HC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.000000e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.000000e-03</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.014</td>\n",
       "      <td>2.100000e-02</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99217838</td>\n",
       "      <td>FU3</td>\n",
       "      <td>6</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>AAM</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-6.000000e-03</td>\n",
       "      <td>3.000000e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>1.387779e-18</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>99677574</td>\n",
       "      <td>FU3</td>\n",
       "      <td>6</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>HC</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-3.000000e-03</td>\n",
       "      <td>-5.000000e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e-03</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-4.000000e-03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>99875982</td>\n",
       "      <td>FU3</td>\n",
       "      <td>6</td>\n",
       "      <td>SVM-rbf</td>\n",
       "      <td>HC</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.400000e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000e-03</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Session  Trial    Model Class  T1w_cor_bankssts-lh-volume  \\\n",
       "0     1163495     FU3      0  SVM-rbf   AAM                       0.008   \n",
       "1     1938036     FU3      0  SVM-rbf   AAM                       0.000   \n",
       "2     2103894     FU3      0  SVM-rbf   AAM                       0.000   \n",
       "3     2766073     FU3      0  SVM-rbf   AAM                       0.006   \n",
       "4     3504454     FU3      0  SVM-rbf    HC                       0.010   \n",
       "..        ...     ...    ...      ...   ...                         ...   \n",
       "97   95957207     FU3      6  SVM-rbf    HC                       0.003   \n",
       "98   97739048     FU3      6  SVM-rbf    HC                       0.000   \n",
       "99   99217838     FU3      6  SVM-rbf   AAM                      -0.006   \n",
       "100  99677574     FU3      6  SVM-rbf    HC                       0.009   \n",
       "101  99875982     FU3      6  SVM-rbf    HC                       0.001   \n",
       "\n",
       "     T1w_cor_caudalanteriorcingulate-lh-volume  \\\n",
       "0                                        0.024   \n",
       "1                                        0.003   \n",
       "2                                       -0.003   \n",
       "3                                        0.007   \n",
       "4                                       -0.008   \n",
       "..                                         ...   \n",
       "97                                       0.009   \n",
       "98                                       0.002   \n",
       "99                                      -0.060   \n",
       "100                                     -0.009   \n",
       "101                                     -0.011   \n",
       "\n",
       "     T1w_cor_caudalmiddlefrontal-lh-volume  T1w_cor_cuneus-lh-volume  \\\n",
       "0                                    0.000              1.000000e-03   \n",
       "1                                    0.001              3.000000e-03   \n",
       "2                                   -0.001              0.000000e+00   \n",
       "3                                    0.000              6.000000e-03   \n",
       "4                                    0.014             -1.387779e-18   \n",
       "..                                     ...                       ...   \n",
       "97                                   0.000              2.000000e-03   \n",
       "98                                   0.002              0.000000e+00   \n",
       "99                                  -0.002             -6.000000e-03   \n",
       "100                                 -0.001             -3.000000e-03   \n",
       "101                                  0.000              0.000000e+00   \n",
       "\n",
       "     T1w_cor_entorhinal-lh-volume  ...  DTI_SFO-R_Average  DTI_SLF_Average  \\\n",
       "0                   -3.000000e-03  ...      -3.000000e-03            0.002   \n",
       "1                    0.000000e+00  ...       0.000000e+00           -0.002   \n",
       "2                    1.000000e-03  ...      -2.000000e-03            0.003   \n",
       "3                   -6.000000e-03  ...      -1.000000e-03           -0.004   \n",
       "4                    5.204170e-19  ...      -2.775558e-18           -0.003   \n",
       "..                            ...  ...                ...              ...   \n",
       "97                   1.300000e-02  ...       5.000000e-03            0.018   \n",
       "98                  -5.000000e-03  ...      -4.000000e-03           -0.012   \n",
       "99                   3.000000e-03  ...       0.000000e+00            0.006   \n",
       "100                 -5.000000e-03  ...      -1.000000e-03           -0.001   \n",
       "101                 -2.400000e-02  ...      -2.000000e-03           -0.006   \n",
       "\n",
       "     DTI_SLF-L_Average  DTI_SLF-R_Average  DTI_SS_Average  DTI_SS-L_Average  \\\n",
       "0               -0.005              0.000           0.000     -4.000000e-03   \n",
       "1                0.000              0.000           0.000      0.000000e+00   \n",
       "2                0.011             -0.003          -0.008     -7.000000e-03   \n",
       "3                0.003              0.000           0.000     -7.000000e-03   \n",
       "4                0.000              0.000           0.001      5.000000e-03   \n",
       "..                 ...                ...             ...               ...   \n",
       "97               0.044             -0.002          -0.001     -6.000000e-03   \n",
       "98              -0.036              0.002           0.014      2.100000e-02   \n",
       "99               0.023             -0.006          -0.017      1.387779e-18   \n",
       "100              0.015              0.004          -0.002     -4.000000e-03   \n",
       "101             -0.020              0.000           0.006      1.000000e-03   \n",
       "\n",
       "     DTI_SS-R_Average  DTI_UNC_Average  DTI_UNC-L_Average  DTI_UNC-R_Average  \n",
       "0               0.001           -0.014              0.003             -0.010  \n",
       "1               0.002            0.001              0.001             -0.005  \n",
       "2               0.000           -0.002             -0.005             -0.005  \n",
       "3               0.000            0.000             -0.002             -0.010  \n",
       "4              -0.005           -0.007             -0.011             -0.008  \n",
       "..                ...              ...                ...                ...  \n",
       "97              0.000            0.003              0.002              0.004  \n",
       "98              0.005            0.004              0.002              0.004  \n",
       "99             -0.001           -0.011              0.011             -0.009  \n",
       "100             0.000           -0.001              0.005             -0.002  \n",
       "101             0.007            0.003              0.000              0.006  \n",
       "\n",
       "[714 rows x 724 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_rbf_FU3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Save the Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5\n",
    "HDF5 = posthoc.read_HDF5('all_Binge.csv')\n",
    "# INSTRUMENT\n",
    "INST = posthoc.read_INSTRUMENT('IMAGEN_INSTRUMENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FU3\n",
    "HDF5_FU3 = HDF5.groupby('Session').get_group('FU3')\n",
    "INST_FU3 = INST.groupby('Session').get_group('FU3')\n",
    "SS_FU3 = pd.merge(HDF5_FU3,INST_FU3, on=['ID','Session'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_FU3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_FU3_Col = list(SS_FU3.columns[:66])+list(SS_FU3.columns[67:70])+list(SS_FU3.columns[71:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = SS_FU3[SS_FU3_Col]\n",
    "SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = f\"{DATA_DIR}/posthoc/IMAGEN_Binge_FU3_SS_ver02.csv\"\n",
    "# if not os.path.isdir(os.path.dirname(save_path)):\n",
    "#     os.makedirs(os.path.dirname(save_path))\n",
    "# SS.to_csv(save_path, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
