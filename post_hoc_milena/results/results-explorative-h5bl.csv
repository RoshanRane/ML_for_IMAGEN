Confound,Conf_time_point,Model,h5name,n_samples BL,Accuracy BL,Std-Dev BL,n_samples CB,Accuracy CB,Std-Dev CB,Accuracy Diff CB - BL,Std-Dev Diff CB - BL,h5cat,category,abs_diff,rank
Alc-last12mntFU3,BL,SVM-rbf,posthoc-cc3-h5bl-Alc-last12mntFU3,620,69.58382756319963,3.2404227443551163,620,62.96752600884672,7.762319677190659,-6.616301554352921,7.053590146803152,h5bl,Alcohol,6.616301554352921,0
Alc-lastmntFU3,BL,SVM-rbf,posthoc-cc3-h5bl-Alc-lastmntFU3,620,69.58382756319963,3.2404227443551163,620,63.220355474831344,5.3752836837804185,-6.363472088368294,4.768245485420295,h5bl,Alcohol,6.363472088368294,1
AgreeablenessFU3,BL,SVM-rbf,posthoc-cc3-h5bl-AgreeablenessFU3,620,69.58382756319963,3.2404227443551163,620,65.05348493834482,3.128459134396012,-4.530342624854811,1.938524130391626,h5bl,Personality,4.530342624854811,2
